<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[采用矿池进行虚拟货币挖矿 v.s 独立挖矿]]></title>
    <url>%2F2018%2F07%2F05%2Fcryptocurrency%2F</url>
    <content type="text"><![CDATA[本文简述了采用矿池挖矿和 Solo 方式挖矿的方法。 综合比较而言，对于小算力的运行环境（1 GH/s），矿池挖矿具有少量的稳定收益（nanopool 为例，约 0.08 ETH/day）。 Solo 方式在主链上与大矿池竞争算力，一天能挖到一个区块的概率不足 2%。 矿池挖矿 v.s 独立挖矿采用矿池进行挖矿该方案可以看做是将算力租借给矿池，矿池根据你贡献的算力给与提成，提成的方式是将挖出的代币按照比例转移到挖矿账户上。这种方案需要的条件包括： 可以挖取代币的硬件环境和挖矿软件 代币地址 可加入的合适矿池 本说明以 nanopool 矿池和基于 MetaMask 的 Ethereum 地址为例对挖矿过程进行阐述。 首先，需要一个可以挖矿的硬件环境，本文默认认为已经有一台安装好 NVIDIA GPU 的服务器。 其次，准备好自己的加密货币地址。该地址可以是交易所的充币地址，可以是 MetaMask 的 Ethereum 地址，还可以是本地钱包的地址，因为最后需要矿池将代币转移给你自己。以 MetaMask 为例，直接复制 Ethernet 的 Address (Copy Address to Clipboard)，可以得到该地址。 再来，需要选择合适的挖矿软件。本文选择如下软件进行挖矿 ethminer 作为 Ethereum 的挖矿软件 xmr-stak 作为 Monero 的挖矿软件 最后，配置好参数运行挖矿软件就可以了。相关配置参数如下： ethminer 的配置参数如下 123456789101112export GPU_FORCE_64BIT_PTR=0export GPU_MAX_HEAP_SIZE=100export GPU_USE_SYNC_OBJECTS=1export GPU_MAX_ALLOC_PERCENT=100export GPU_SINGLE_ALLOC_PERCENT=100addr=....worker=....email=...../ethminer --farm-recheck 2000 -U \ -P stratum1+tcp://$&#123;addr&#125;@eth-asia1.nanopool.org:9999/$&#123;worker&#125;/$&#123;email&#125; xmr-stak 的配置参数如下 12345addr=....worker=....email=...../xmr-stak -O xmr-asia1.nanopool.org:14433 -u $&#123;addr&#125;.$&#123;worker&#125;/$&#123;email&#125; --currency monero7 值得注意的是上述配置中的 worker 和 email 需要正确填写，之后在 nanopool 网站上，根据这两个值可以调整最小提取额度。 收益以 ETH 为例。 nanopool 在7月9日当天的 ETH 平均算力为 42122.7 Gh/s，每 24 小时挖到的普通块数为 686，叔块数为 315。 省略叔块的奖励，在当天 1 Gh/s 的算力情况下，可以分得的收益为 $ 5 \times 686/42122.7=0.081428778 $ ETH。 独立节点挖矿独立挖矿的好处在于挖到 Eth 所得的奖励独享，坏处在于需要与大矿池竞争算力。本文中设置的挖矿拓扑为一个主网节点和多个挖矿节点。其中，主网节点用来同步全账本信息，运行 geth 程序；挖矿节点仅负责计算，运行 ethminer 程序。以下是账本同步与挖矿运行的脚步： 1234567891011121314151617181920212223242526# 主网同步节点./bin/geth --rpc \ --syncmode "fast" \ --rpcaddr "0.0.0.0" \ --rpcport "8545" \ --rpccorsdomain "*" \ --datadir "/mnt/data/eth-data/data" \ --ethash.dagdir "/mnt/data/eth-data/dag" \ --etherbase "..." \ --rpcapi "personal,db,eth,net,web3" \ console 2&gt;&amp;1 | tee geth.log # 主网节点开放端口sudo iptables -A INPUT -p tcp \ --dport 8545 -m conntrack \ --ctstate NEW,ESTABLISHED -j ACCEPT或sudo ufw allow 8545# 挖矿节点wallet_addr="..."ethnet_addr="..."## use nvidia gpu./ethminer --farm-recheck 2000 \ -U -P http://$&#123;wallet_addr&#125;@$&#123;ethnet_addr&#125; 关于挖矿的可能性可以参考 Ethereum 的算力统计图。 从15年以来，入块的最低算力是 11.5297 GH/s。 以 7月9日当天的平均算力为 292711.4538 GH/s。 如果是 1GH/s 的算力在7月9日当天挖到一个区块的可能性为 $ 1/292711.4538 \times (60 \times 60 \times 24)/15=0.019678082 $ （ETH 区块产生速率为 15 秒一个 Block）。 参考资料 Ethereum Homestead中文文档/挖矿 MathJax.Hub.Config({ extensions: ["tex2jax.js"], jax: ["input/TeX", "output/HTML-CSS"], tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], }, "HTML-CSS": { availableFonts: ["TeX"] } });]]></content>
      <categories>
        <category>funny</category>
      </categories>
      <tags>
        <tag>cryptocurrency</tag>
        <tag>mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Express + MongoDB + PugJs 开发总结]]></title>
    <url>%2F2018%2F03%2F23%2Fexpress-mongodb-website%2F</url>
    <content type="text"><![CDATA[前段时间用 Express (PugJS) + MongoDB + Scrapy 建了一个视频索引网站。现在简单总结一下。 搭建网站前端开发首先，不得不说使用 MongoDB 建站是一件很方便的事情。后台 Model 有任何改动，只需要在 mongoose 加一个字段就可以了，相比于关系型数据库的严格类型约束，Object DB 更适合迭代开发。不过在性能上 mongodb 在后期有些吃力，特别是服务器配置不高的时候，mongodb 对内存的压力还是不小，不过这都是后话。在实现 search 和 related document 功能的时候，偷懒使用 MongoDB 的全文检索功能，性能不高，基本可以，适用于原型设计。 其次，Express 管理服务端逻辑。我采用传统的 MVC 将文件分为 controller、model、view 三个部分。controller 负载页面响应和数据获取，model 就是定义 mongoose 中 document 的字段，以及一些基本的存储逻辑（比如用户登录的密码验证，加密等操作），view 这部分我采用的 pugjs 进行前端页面渲染，pugjs 本质上还是 javascript 所以操作前端页面按照 JS 的逻辑来写就行了，不过开发过程中自己会把很多字符串处理逻辑都写在 PUG 中，感觉不是太好。 再次，就是前端 JS 的 IE 兼容问题。因为习惯使用 es2015 来写，在实际运行的时候发现在 chrome、firefox 下跑的很好，但是在 IE 上就出现各种问题。解决方法是用 babel 的 es2015-ie 插件进行兼容转换。 最后，Mobile 和 Destop 的支持，采用 Bootstrap 进行响应式布局，对于 CSS 不是特别熟悉，所以没有过多的研究响应式布局的细节。 数据获取建站的前提是有稳定的数据源，因为自己不做 CMS，所以内容方面全部依赖爬取站点的内容质量。在此，不做详述。 数据爬取使用 scrapy 框架，只是使用了基本的功能。对于分布式、IP 池等没有涉及。每个站点都写了一个 Spider。从 Spider 到 Server Model 还有一段路要走，也就是说爬下来的时候需要清洗才能入库呈现。这部分的 pipeline 我是这么设计的： scrapy 爬取元数据，包括视频播放连接和元信息两部分； 经过 join 将视频信息和元信息进行合并，然后剔除不符合要求的数据，进入 model 库； 对数据进行回查，相当于是对 model 库进行清洗，主要就是剔除失效的视频连接，这部分可以定期处理（一个简单粗暴的 CMS 功能）。 写在最后至此，站点就被搭建起来了，是不是很简单。因为没有数据维护（或者可以说是很简单的数据维护），一切数据依赖被爬取站点的数据质量。这种寄人篱下的站点建设方法不知道什么时候就会因为目标网站的升级需要更新自己的 spider 逻辑。 而且，随着 mongodb 中的数据越来越多，查询性能和 search 性能都在下降（前提是服务器不升级，512 MB 内存 1 CPU，6万多条记录，related search 的响应时间在 10-20 sec，find by index 的响应时间在 1-3 sec， findById 的的响应时间在 200-600 ms）。 此外，网站监控使用第三方服务，包括 google analysis、whos.amung.us、histats、clustrmaps 等，whos 主要监控实时的视频播放人数，histats 监控网站的访问，clustrmaps 这个主要是对旧版页面的监控。google analysis 分析整个网站的访问情况。 SEO：设置了 sitemap 和 robots，对页面的 meta 进行了简单的设计，但效果不是太理想，现在也在摸索。 反爬虫：还没做。 未来发展这个站点就这样了吧，作为一个练手的站点，未来最多也就是更新数据源了。不过以后想用 vue 或者 react 写个单页面的网站。将前端和后端数据完全分离，现在 pug 渲染的时候，还是会将一部分 control 逻辑混写在 view 中。期待前后端数据和渲染的完全分离。 最后贴一个现在 clustrmaps 统计的访问情况，以示纪念。]]></content>
      <categories>
        <category>development</category>
      </categories>
      <tags>
        <tag>express</tag>
        <tag>mongodb</tag>
        <tag>pugjs</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 使用笔记]]></title>
    <url>%2F2017%2F11%2F01%2Fmac-usage%2F</url>
    <content type="text"><![CDATA[使用 Mac 时的一些经验分享 关于代理科学上网（shadowsocks + VPS）搭建 shadowsocks 代理服务器在 DigitalOcean 买一个 VPS（5$/mo），然后安装 shadowsocks，网上有很多教程（例如 这个），再次不再累述。贴两个自己的配置。其中一个是用 supervisor 管理 shadowsocks 服务的配置文件。 123456789101112131415161718192021# cat /etc/supervisor/conf.d/shadowsocks.conf[program:shadowsocks]command=ssserver -c /etc/shadowsocks.jsonautorestart=trueuser=nobodystdout_logfile=/tmp/shadowsocks.out.logstderr_logfile=/tmp/shadowsocks.err.log# cat /etc/shadowsocks.json&#123; &quot;server&quot;:&quot;::&quot;, &quot;server_port&quot;:8836, &quot;local_port&quot;:1080, &quot;password&quot;: &quot;xx_x_xx&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false, &quot;prefer_ipv6&quot;: true&#125; 本地下载安装 shadowsocks 客户端，然后如下图所示进行配置。 使用 Proxifier 全局代理shadowsocks 只能实现 socks 代理，限制了很多应用的使用。Proxifier 可以让不支持通过代理服务器工作的网络程序能通过HTTPS或SOCKS代理。 Proxifier 的使用非常简单，装好之后写 rules 就可以了。如下图所示，目前我只是将 Google Drive 的请求转发到 socks 上 让 iOS 使用 SSH 代理访问 Web 服务思路是在本地局域网内想办法建立一个 SSH 代理，然后让 iOS 设备将请求转发到这个代理上。 我们在一台 Macbook 和一个 iPad 的环境下实现这样的操作。具体操作步骤如下： 在 Macbook（IP 地址是 192.168.0.8） 上搭建一个 SSH 代理 ssh -g -N -D 192.168.0.8:8000 mypc # -g 表示外部机器可以连到这个地址 创建一个PAC文件 proxy.pac，指定如何配置proxy。 123function FindProxyForURL(url, host) &#123; return &quot;SOCKS 192.168.0.8:8000&quot;;&#125; 在 Macbook 上开启 web 服务，并将 proxy 文件放在 web 服务上。 cp proxy.pac /Library/WebServer/Documents sudo apachectl start 可以通过 http://192.168.0.8/proxy.pac 访问这个代理文件。 在iOS上设置。 通过“Settings”-&gt;”WLAN Networks”找到现在连上的Wifi，查看details（蓝色箭头）在最下面有设置http proxy的地方。选择”Auto”, 填入 http://192.168.0.8/proxy.pac （注意：需要添加 http 头） Done！ 这样在 Macbook 开启代理的情况下，iOS 设备可以通过该代理访问web服务。 参考： Mac OS X 启用 Web 服务器 让iOS使用SSH Tunnel 关于工具 Alfred 常用插件 Dict Kill Process TerminalFinder IP Address Atom 常用插件 atom-beautify autocomplete-python vim-mode-plus platformio-ide-terminal go-plus Remote FTP Visual Studio Code Zotero (这在 Zotero 使用笔记 讲过) Vim 环境配置使用 The Ultimate vimrc Emacs 环境配置使用 spacemacs]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>usage-notes</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH 转发与代理]]></title>
    <url>%2F2017%2F10%2F17%2Fssh-proxy%2F</url>
    <content type="text"><![CDATA[利用 SSH 可以方便的搭建本地代理访问互联网。本文介绍如何跨节点访问远程主机，并在此基础上建立代理。 Secure Shell（缩写为SSH），由IETF的网络工作小组（Network Working Group）所制定；SSH为一项创建在应用层和传输层基础上的安全协议，为计算机上的Shell（壳层）提供安全的传输和使用环境。— from wikipedia 基于 SSH 的本地代理使用 SSH 进行本地转发在命令行执行如下命令 1$ ssh -N -D 8000 &lt;remote-host&gt; 这行命令的意思是在本地开放一个转发端口（-D） 8000，将发送到这个端口的信息转发（-N）给远程主机（&lt;remote-host&gt;）。 这相当于在本地建立了一个监听 8000 端口的代理服务。 在 Chrome 浏览器中，安装 SwitchyOmega 插件，建立一个 profile 是在本机 8000 端口使用 socks5 协议的代理，取名为 proxy8000。之后，浏览 web 的时候选择 proxy8000，便可以将请求通过 remote-host 进行转发访问了。 SSH 代理当前从A登录到C需要先登录B再登录C，如下图所示 12345+-----+ +-----+ +-----+| | | | | || A +-----------&gt; | B +-----------&gt; | C || | | | | |+-----+ +-----+ +-----+ 我们的任务是通过A直接登录C 12345+-----+ +-----+ +-----+| | | | | || A +-------------------------------&gt; | C || | | | | |+-----+ +-----+ +-----+ 思路是建立 SSH 代理。在本地编辑 ~/.ssh/config 文件，增加 ProxyCommand 选项，像下面这样： 123456Host target.machine User targetuser HostName target.machine IdentityFile %d/.ssh/id_rsa ProxyCommand ssh proxyuser@proxy.machine -W %h:%p 示例（注意分隔符是 tab 不是空格，粘贴后请自行修改）： 123456Host mypc User lf HostName 10.2.5.160 IdentityFile %d/.ssh/id_rsa # ProxyCommand ssh proxyuser@proxy.machine nc %h %p 2&gt; /dev/null ProxyCommand ssh nbtest@172.22.1.21 -W %h:%p 相当于我们以 nbtest 用户登录到 172.22.1.21 服务器上，再以 lf 用户登录到 10.2.5.160 上。如果从本地可以免秘钥访问 nbtest@172.22.1.21 服务器，那么我们在命令行键入 ssh mypc 的时候直接输入 lf 的登录密码即可登录到 10.2.5.160 服务器上。 跨节点转发与2中所述的网络结构一样。我们有些服务在 B 上不能访问，在 C 上可以访问。按照2，在 B 上，建立 A 到 C 的代理，然后在 A 建立通过 C 的转发服务，即可访问 C 上可访问的资源。 1$ ssh -N -D 8000 &lt;remote-C-host&gt;]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>usage-notes</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zotero 使用笔记]]></title>
    <url>%2F2017%2F10%2F13%2Fzotero-notes%2F</url>
    <content type="text"><![CDATA[Zotero 是一个免费的文献管理工具。关于 Zotero 的使用推荐阳志平老师的博客： (1) 文献管理软件Zotero基础及进阶示范 (2) 作为知识管理工具的Zotero (3) 平板与社交：再谈研究辅助工具Zotero兼配套APP (4) Zotero之Zotfile插件的使用 (5) 电子文献管理攻略 (6) 如何批量下载PDF 本文主要介绍几个比较有用的插件和自己平时的操作流程。 插件Zotfile (link)主要功能包括，文件重命名，导出 PDF 文件到指定目录，与云存储配合实现扩平台阅读。 Better Bib(La)Tex（link）(已过时，zotero 支持 clipboard 导入，看 tips5 )Zotero 本身不支持 Bibtex 格式导入文章条目。该插件弥补了这一不足。 使用时，将 Bibtex 信息复制到 clipboard 中，然后选择 import from clipboard 即可。 Markdown Here（link）使用 markdown 编写文章笔记，然后用 ctrl+alt+m 组合键将文本变为 html。该插件需要自行编译 xpi 插件包。 Google Scholar Citation（link）查找文章的引用数，将引用信息填入 extra 字段中。 P.S. 最新版本的插件可能会不工作，可以使用老版本的插件(例如 v1.8.4)。如果一次更新太多会被 Google 认为是 Robot，限制访问。 工作流[预备] 同步到 webDAV 上（使用 digital ocean 的私服搭建） 文件导入（一般是 connector 或 bibtex）； 批量下载 （chrono download），并创建索引（Create Bibliography from Item）； 更新 scholar citation（Google Scholar Citation）； 使用 Zotfile 发送到共享文件夹 （Google Drive），使用 IPad 浏览（PDF Expert）并记录笔记然后再用 Zotfile [Get from Tablet] 同步回 Zotero； 在条目中创建 notes ，使用 markdown 语法做笔记（markdown here）。 另外，阳的博客（6）中使用的 chrome 插件已经过时，更新为 Chrono Download Manager。 Tips 递归显示 collection 中所有项目信息 (Hidden Perferences) 希望实现的功能是，点击一个 collection 可以显示 sub-collection 的项目。Zotero 默认情况是不显示的。这个问题之前有人在 Zotero 社区问过。 解决方法是通过修改 Hidden Preference 文件中的 extensions.zotero.recursiveCollections 字段，将其修改为 true 即可。 Zotero 的配置文件包括一般可用文件和隐藏文件。隐藏文件的修改可以进入 Advanced (Panel)，选择 open:config 进行修改（当前 Zotero 版本是 4.0.29.15）。 显示 collection 目录下文件个数 (tips_and_tricks) To see how many items you have, click an item in the middle pane and Select All (Command-A on macOS or Control-A on Windows/Linux). A count of selected items will appear in the right-hand pane. 批量展开与折叠项目信息 To determine total items, including child attachments and notes, click an item and press the + (plus) key to expand all parent items before using Select All. You can press - (minus) afterward to collapse all items. 查看一个条目在哪些目录（tips_and_tricks） To see all the collections an item is in, select the item and then hold down the “Option” key (Mac OS X), “Control” key (Windows), or “Alt” key (Linux). This will highlight all collections that contain the selected item. 从粘贴板导入条目（How does the Import from Clipboard feature work?） Import from Clipboard allows you to import items from the raw code of any supported format (RIS, BibTeX, CSL JSON, etc.). Many websites post the bibliographic data for items in their raw form. To add these items to your Zotero library, select and copy the code from the site, then import through the option in File menu in Zotero, or by the keyboard shortcut (Windows/Linux: Ctrl-Alt-Shift-I / Mac: Cmd-Option-Shift-I). TODO List关于插件： voyant-export 可以对储存在Zotero里的文字信息进行进一步分析，生成云图或者其它数据可视化图像。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>zotero</tag>
        <tag>usage-notes</tag>
      </tags>
  </entry>
</search>
